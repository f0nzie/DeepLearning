---
title: "R Notebook"
output: html_notebook
---

Source: https://tsmatz.wordpress.com/2017/02/10/scale-out-mxnet-r-deep-learning-scoring-with-azure-hadoop-rserver/

[Handwritten Digits Classification Competition](http://mxnet.io/tutorials/r/mnistCompetition.html)


```{r}
require(mxnet)

train <- read.csv("train.csv", header=TRUE)
train <- data.matrix(train)

# separate label and pixel
train.x <- train[,-1]
train.y <- train[,1]

# transform image pixel [0, 255] into [0,1]
train.x <- t(train.x/255)
```

```{r}
# configure network
data <- mx.symbol.Variable("data")
fc1 <- mx.symbol.FullyConnected(data, name="fc1", num_hidden=128)
act1 <- mx.symbol.Activation(fc1, name="relu1", act_type="relu")
fc2 <- mx.symbol.FullyConnected(act1, name="fc2", num_hidden=64)
act2 <- mx.symbol.Activation(fc2, name="relu2", act_type="relu")
fc3 <- mx.symbol.FullyConnected(act2, name="fc3", num_hidden=10)
softmax <- mx.symbol.SoftmaxOutput(fc3, name="sm")

```

```{r}
# train !
# (If you want to use gpu, please set like ctx=list(mx.gpu(0),mx.gpu(1)) )
mx.set.seed(0)
model <- mx.model.FeedForward.create(
  softmax,
  X=train.x,
  y=train.y,
  # ctx=mx.cpu(),
  ctx=list(mx.gpu(0)),
  num.round=10,
  array.batch.size=100,
  learning.rate=0.07,
  momentum=0.9,
  eval.metric=mx.metric.accuracy,
  initializer=mx.init.uniform(0.07),
  epoch.end.callback=mx.callback.log.train.metric(100))

```

```{r}
#####
# read scoring data
#
# test.csv is:
# (pixel0, pixel1, ..., pixel783)
# 0, 0, ..., 0
# 0, 0, ..., 0
# ...
#####
test <- read.csv("test.csv", header=TRUE)
test <- data.matrix(test)
test <- t(test/255)

# score !
# ("preds" is the matrix of the possibility of each number)
preds <- predict(model, test)

#####
# output result (occurance count of each number)
#
# The result is:
#    0    1    2 ...     9
# 2814 3168 2711 ...  2778 
#####
pred.label <- max.col(t(preds)) - 1
table(pred.label)
```

```{r}
#20170209_Sample_Network_zpsoymfmv23.jpg
```

